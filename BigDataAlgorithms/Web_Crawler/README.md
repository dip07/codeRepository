This is a programming assignment that I did in course Algorithm for Large DataSets My teammate Gaurav Bhatt is also a collaborator in this assignment.
In this project, we need to crawl Wikipedia pages, and search for pages which are relevant to the topics. We should be scrolling only certain number of web pages. The project requires not to visit the disallowed pages and to pause for some time after a certain number of request has been sent.
We need to ignore certain links on the Wikipedia pages and only check the links which redirects to Wikipedia pages. We found that significant time is taken by the webcrawler in downloading the web pages. 
######Please note that this is an academic project
